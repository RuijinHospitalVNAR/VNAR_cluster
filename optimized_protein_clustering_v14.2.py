class ProteinClusterAnalyzer:
    def __init__(self, cif_dir, antibody_chain='A', antigen_chains=['B', 'C'], 
                 dist_cutoff=5.0, n_jobs=-1):
        """
        åˆå§‹åŒ–è›‹ç™½è´¨èšç±»åˆ†æå™¨
        
        Parameters:
        -----------
        cif_dir : str
            CIF/PDBæ–‡ä»¶ç›®å½•è·¯å¾„
        antibody_chain : str
            æŠ—ä½“é“¾ID
        antigen_chains : list
            æŠ—åŸé“¾IDåˆ—è¡¨
        dist_cutoff : float
            è·ç¦»æˆªæ–­å€¼
        n_jobs : int
            å¹¶è¡Œå¤„ç†æ•°é‡ï¼Œ-1è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰CPU
        """
        self.cif_dir = Path(cif_dir)
        self.antibody_chain = antibody_chain
        self.antigen_chains = antigen_chains
        self.dist_cutoff = dist_cutoff
        self.n_jobs = n_jobs if n_jobs != -1 else cpu_count()
        
        # HDBSCANå‚æ•°
        self.min_cluster_size = 10
        self.min_samples = 5
        self.cluster_selection_epsilon = 0.1
        
        # æ•°æ®å­˜å‚¨
        self.contact_maps = []
        self.feature_vectors = []
        self.file_names = []
        self.cluster_labels = None
        self.scaler = StandardScaler()
        
        # åˆ é™¤æ°¨åŸºé…¸æ€§è´¨å­—å…¸è®¾ç½®
        # self._setup_amino_acid_properties()
        
    # åˆ é™¤æ•´ä¸ª_setup_amino_acid_propertiesæ–¹æ³•
    
    def extract_ca_coords_with_residues(self, structure_file, chain_ids):
        """æå–æŒ‡å®šé“¾çš„CÎ±åŸå­åæ ‡å’Œæ®‹åŸºä¿¡æ¯ï¼Œè¿”å›(resname, resid, chain)"""
        try:
            ext = str(structure_file).split('.')[-1].lower()
            if ext == "pdb":
                parser = PDBParser(QUIET=True)
            else:
                parser = MMCIFParser(QUIET=True)
            structure = parser.get_structure('model', structure_file)

            ca_coords = []
            residue_infos = []
            chain_info = {}
            found_chains = set()

            for model in structure:
                for chain in model:
                    if chain.id in chain_ids:
                        found_chains.add(chain.id)
                        chain_coords = []
                        chain_residues = []
                        for res in chain:
                            if 'CA' in res:
                                coord = res['CA'].get_coord()
                                resname = res.get_resname().strip()  # å»é™¤ç©ºæ ¼
                                resid = res.id[1]
                                chain_id = chain.id
                                chain_coords.append(coord)
                                chain_residues.append((resname, resid, chain_id))
                        if chain_coords:
                            ca_coords.extend(chain_coords)
                            residue_infos.extend(chain_residues)
                            chain_info[chain.id] = len(chain_coords)

            missing = set(chain_ids) - found_chains
            if missing:
                logger.warning(f"Chains {missing} not found in {structure_file}")

            return np.array(ca_coords), residue_infos, chain_info
        except Exception as e:
            logger.warning(f"Error processing {structure_file}: {e}")
            return np.array([]), [], {}

    def compute_contact_map_with_residues(self, coords_ab, coords_ag, residues_ab, residues_ag):
        """è®¡ç®—contact mapå¹¶è¿”å›æ¥è§¦æ®‹åŸºä¿¡æ¯"""
        if len(coords_ab) == 0 or len(coords_ag) == 0:
            return np.array([]), [], []
        
        # è®¡ç®—è·ç¦»çŸ©é˜µ
        dists = np.linalg.norm(coords_ab[:, None, :] - coords_ag[None, :, :], axis=-1)
        contact_map = (dists < self.dist_cutoff).astype(np.float32)
        
        # è·å–æ¥è§¦æ®‹åŸº
        contact_rows, contact_cols = np.where(contact_map > 0)
        contact_ab_residues = [residues_ab[i][0] for i in contact_rows]  # åªå–æ®‹åŸºåç§°
        contact_ag_residues = [residues_ag[i][0] for i in contact_cols]
        
        return contact_map, contact_ab_residues, contact_ag_residues

    def extract_interaction_features(self, contact_map, contact_ab_residues, contact_ag_residues):
        """ä»contact mapæå–å‡ ä½•ç‰¹å¾"""
        if contact_map.size == 0:
            return np.zeros(15)  # è¿”å›å›ºå®šé•¿åº¦çš„é›¶å‘é‡ï¼ˆ15ä¸ªç‰¹å¾ï¼‰
        
        features = []
        
        # 1. åŸºæœ¬å‡ ä½•ç‰¹å¾
        features.extend([
            np.sum(contact_map),  # æ€»æ¥è§¦æ•°
            np.mean(contact_map),  # æ¥è§¦å¯†åº¦
            np.std(contact_map),   # æ¥è§¦å˜å¼‚æ€§
        ])
        
        # 2. è¡Œåˆ—ç»Ÿè®¡ï¼ˆæŠ—ä½“å’ŒæŠ—åŸæ®‹åŸºçš„æ¥è§¦æ¨¡å¼ï¼‰
        row_sums = np.sum(contact_map, axis=1)
        col_sums = np.sum(contact_map, axis=0)
        
        features.extend([
            np.mean(row_sums) if len(row_sums) > 0 else 0, 
            np.std(row_sums) if len(row_sums) > 0 else 0, 
            np.max(row_sums) if len(row_sums) > 0 else 0,
            np.mean(col_sums) if len(col_sums) > 0 else 0, 
            np.std(col_sums) if len(col_sums) > 0 else 0, 
            np.max(col_sums) if len(col_sums) > 0 else 0,
        ])
        
        # 3. æ¥è§¦åŒºåŸŸçš„å‡ ä½•ç‰¹å¾
        if np.sum(contact_map) > 0:
            contact_rows, contact_cols = np.where(contact_map > 0)
            features.extend([
                np.std(contact_rows) if len(contact_rows) > 0 else 0,  # æŠ—ä½“æ¥è§¦åŒºåŸŸåˆ†æ•£åº¦
                np.std(contact_cols) if len(contact_cols) > 0 else 0,  # æŠ—åŸæ¥è§¦åŒºåŸŸåˆ†æ•£åº¦
                len(np.unique(contact_rows)),  # å‚ä¸æ¥è§¦çš„æŠ—ä½“æ®‹åŸºæ•°
                len(np.unique(contact_cols)),  # å‚ä¸æ¥è§¦çš„æŠ—åŸæ®‹åŸºæ•°
            ])
        else:
            features.extend([0, 0, 0, 0])
        
        # 4. æ¥è§¦æ¨¡å¼ç‰¹å¾ï¼ˆå±€éƒ¨è¿ç»­æ€§ï¼‰
        if contact_map.shape[0] > 1 and contact_map.shape[1] > 1:
            row_continuity = np.sum(contact_map[:-1, :] * contact_map[1:, :])
            col_continuity = np.sum(contact_map[:, :-1] * contact_map[:, 1:])
            features.extend([row_continuity, col_continuity])
        else:
            features.extend([0, 0])
        
        return np.array(features, dtype=np.float32)
    
    # åˆ é™¤æ‰€æœ‰æ°¨åŸºé…¸æ€§è´¨ç›¸å…³çš„æ–¹æ³•ï¼š
    # - extract_amino_acid_features
    # - _get_residue_properties
    # - _calculate_charge_complementarity
    # - _calculate_hydrophobic_interaction
    # - _calculate_polar_interaction
    # - _calculate_interface_complementarity

    def process_single_file(self, structure_file):
        """å¤„ç†å•ä¸ªç»“æ„æ–‡ä»¶"""
        try:
            # æå–åæ ‡å’Œæ®‹åŸºä¿¡æ¯
            ab_coords, ab_residues, ab_info = self.extract_ca_coords_with_residues(structure_file, [self.antibody_chain])
            ag_coords, ag_residues, ag_info = self.extract_ca_coords_with_residues(structure_file, self.antigen_chains)
            
            if len(ab_coords) == 0 or len(ag_coords) == 0:
                logger.warning(f"No valid coordinates found in {structure_file}")
                return None, None, None
            
            # è®¡ç®—contact mapå’Œæ¥è§¦æ®‹åŸº
            contact_map, contact_ab_residues, contact_ag_residues = self.compute_contact_map_with_residues(
                ab_coords, ag_coords, ab_residues, ag_residues)
            
            if contact_map.size == 0:
                return None, None, None
            
            # æå–å‡ ä½•ç‰¹å¾ï¼ˆä¸åŒ…å«æ°¨åŸºé…¸æ€§è´¨ï¼‰
            features = self.extract_interaction_features(contact_map, contact_ab_residues, contact_ag_residues)
            
            return contact_map.flatten(), features, structure_file.name
            
        except Exception as e:
            logger.error(f"Error processing {structure_file}: {e}")
            return None, None, None

    # ... existing code ...

    def visualize_results(self, X, save_path=None):
        """å¯è§†åŒ–èšç±»ç»“æœ"""
        if self.cluster_labels is None:
            raise ValueError("No clustering results found.")
        
        # ä½¿ç”¨æ›´å®‰å…¨çš„matplotlibæ ·å¼
        try:
            plt.style.use('seaborn-v0_8')
        except:
            plt.style.use('default')
            
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Protein Complex Clustering Results', fontsize=16)
        
        unique_labels = np.unique(self.cluster_labels)
        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))
        
        # 1. èšç±»æ ‡ç­¾åˆ†å¸ƒ
        ax1 = axes[0, 0]
        for label, color in zip(unique_labels, colors):
            mask = self.cluster_labels == label
            indices = np.where(mask)[0]
            ax1.scatter(indices, [label] * len(indices), 
                       c=[color], alpha=0.7, s=30,
                       label=f'Cluster {label}' if label != -1 else 'Noise')
        ax1.set_xlabel('Sample Index')
        ax1.set_ylabel('Cluster Label')
        ax1.set_title('Cluster Assignment')
        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # 2. èšç±»å¤§å°åˆ†å¸ƒ
        ax2 = axes[0, 1]
        cluster_sizes = []
        cluster_ids = []
        for label in unique_labels:
            if label != -1:
                size = np.sum(self.cluster_labels == label)
                cluster_sizes.append(size)
                cluster_ids.append(label)
        
        if cluster_sizes:
            bars = ax2.bar(range(len(cluster_sizes)), cluster_sizes, 
                          color=colors[unique_labels != -1])
            ax2.set_xlabel('Cluster ID')
            ax2.set_ylabel('Cluster Size')
            ax2.set_title('Cluster Size Distribution')
            ax2.set_xticks(range(len(cluster_ids)))
            ax2.set_xticklabels(cluster_ids)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, size in zip(bars, cluster_sizes):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                        str(size), ha='center', va='bottom')
        
        # 3. t-SNEå¯è§†åŒ–
        ax3 = axes[1, 0]
        if len(X) > 1:
            try:
                perplexity = min(30, max(5, len(X) - 1))
                tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)
                X_tsne = tsne.fit_transform(X)
                
                for label, color in zip(unique_labels, colors):
                    mask = self.cluster_labels == label
                    ax3.scatter(X_tsne[mask, 0], X_tsne[mask, 1], 
                               c=[color], alpha=0.7, s=30,
                               label=f'Cluster {label}' if label != -1 else 'Noise')
                ax3.set_xlabel('t-SNE 1')
                ax3.set_ylabel('t-SNE 2')
                ax3.set_title('t-SNE Visualization')
                ax3.legend()
            except Exception as e:
                ax3.text(0.5, 0.5, f't-SNE failed: {str(e)}', 
                        ha='center', va='center', transform=ax3.transAxes)
        
        # 4. ç‰¹å¾é‡è¦æ€§ï¼ˆåªåŒ…å«å‡ ä½•ç‰¹å¾ï¼‰
        ax4 = axes[1, 1]
        if hasattr(self, 'feature_vectors') and len(self.feature_vectors) > 0:
            feature_matrix = np.array(self.feature_vectors)
            
            # å®šä¹‰ç‰¹å¾åç§°ï¼ˆåªåŒ…å«å‡ ä½•ç‰¹å¾ï¼‰
            geometric_features = [
                'Total_Contacts', 'Contact_Density', 'Contact_Variability',
                'Ab_Mean_Contacts', 'Ab_Std_Contacts', 'Ab_Max_Contacts', 
                'Ag_Mean_Contacts', 'Ag_Std_Contacts', 'Ag_Max_Contacts',
                'Ab_Region_Dispersion', 'Ag_Region_Dispersion', 
                'Ab_Residue_Count', 'Ag_Residue_Count',
                'Ab_Continuity', 'Ag_Continuity'
            ]
            
            # ç¡®ä¿ç‰¹å¾åç§°æ•°é‡ä¸å®é™…ç‰¹å¾æ•°é‡åŒ¹é…
            if len(geometric_features) != feature_matrix.shape[1]:
                geometric_features = [f'Feature_{i}' for i in range(feature_matrix.shape[1])]
            
            # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„æ–¹å·®
            feature_variance = np.var(feature_matrix, axis=0)
            sorted_indices = np.argsort(feature_variance)[::-1][:15]  # å‰15ä¸ªæœ€é‡è¦çš„ç‰¹å¾
            
            bars = ax4.barh(range(len(sorted_indices)), 
                           feature_variance[sorted_indices])
            ax4.set_yticks(range(len(sorted_indices)))
            ax4.set_yticklabels([geometric_features[i] for i in sorted_indices])
            ax4.set_xlabel('Variance')
            ax4.set_title('Top 15 Feature Importance')
            
            # æ‰€æœ‰ç‰¹å¾éƒ½ç”¨è“è‰²ï¼ˆå‡ ä½•ç‰¹å¾ï¼‰
            for bar in bars:
                bar.set_color('skyblue')
                    
        else:
            ax4.text(0.5, 0.5, 'No engineered features available', 
                    ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('Feature Importance')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"Visualization saved to {save_path}")
        
        plt.show()

    # åˆ é™¤analyze_amino_acid_patternsæ–¹æ³•

    def main():
        """ä¸»å‡½æ•°"""
        # é…ç½®å‚æ•°
        CIF_DIR = "./your_structure_dir"  # ä¿®æ”¹ä¸ºä½ çš„ç»“æ„æ–‡ä»¶å¤¹è·¯å¾„
        ANTIBODY_CHAIN = 'A'
        ANTIGEN_CHAINS = ['B', 'C']
        DIST_CUTOFF = 5.0
        
        # åˆ›å»ºåˆ†æå™¨
        analyzer = ProteinClusterAnalyzer(
            cif_dir=CIF_DIR,
            antibody_chain=ANTIBODY_CHAIN,
            antigen_chains=ANTIGEN_CHAINS,
            dist_cutoff=DIST_CUTOFF,
            n_jobs=-1
        )
        
        try:
            # åŠ è½½å’Œå¤„ç†æ•°æ®
            cache_file = "protein_data_cache.pkl"
            analyzer.load_and_process_data(cache_file=cache_file)
            
            # å‡†å¤‡ç‰¹å¾ï¼ˆåªåŒ…å«å‡ ä½•ç‰¹å¾å’Œæ¥è§¦ç‰¹å¾ï¼‰
            X = analyzer.prepare_features(feature_type='combined', use_pca=True)
            
            # æ‰§è¡Œèšç±»
            cluster_labels = analyzer.perform_clustering(X, method='hdbscan')
            
            # è¯„ä¼°èšç±»è´¨é‡
            metrics = analyzer.evaluate_clustering(X)
            
            # å¯è§†åŒ–ç»“æœ
            analyzer.visualize_results(X, save_path='clustering_results.png')
            
            # åˆ é™¤æ°¨åŸºé…¸æ€§è´¨åˆ†æ
            # aa_analysis = analyzer.analyze_amino_acid_patterns(save_path='amino_acid_analysis.png')
            
            # ä¿å­˜ç»“æœ
            analyzer.save_results('clustering_results.pkl', X)
            
            # è¾“å‡ºä»£è¡¨æ€§æ ·æœ¬
            representatives = analyzer.get_cluster_representatives(X)
            print("\nå„èšç±»ä»£è¡¨æ€§æ ·æœ¬ï¼š")
            for label, info in representatives.items():
                print(f"Cluster {label} ({info['size']} samples):")
                for i, (file, dist) in enumerate(zip(info['files'], info['distances'])):
                    print(f"  {i+1}. {file} (distance to center: {dist:.3f})")
                print()
            
            print("\nğŸ§¬ èšç±»åˆ†æå®Œæˆï¼")
            print("ğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
            print("  - clustering_results.png: èšç±»å¯è§†åŒ–")
            print("  - clustering_results.pkl: å®Œæ•´ç»“æœ")
            print("  - clustering_results.csv: ç»“æœè¡¨æ ¼")
            
        except Exception as e:
            logger.error(f"Analysis failed: {e}")
            raise